{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ebe59d9-d8c7-4ce2-b437-e3f4e2af968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import cohere\n",
    "\n",
    "# Inicializar Cohere\n",
    "co = cohere.Client('OUxseEdjMfnqbmNkjQcNOcbLKkjFwHREtRJq72ZS')\n",
    "\n",
    "# Cargar los datos desde el archivo JSON\n",
    "with open('data.json', 'r', encoding='utf-8') as f:\n",
    "    faqs = json.load(f)\n",
    "\n",
    "# Extraer preguntas y respuestas\n",
    "preguntas = [faq['pregunta'] for faq in faqs]\n",
    "respuestas = [faq['respuesta'] for faq in faqs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13ece2b6-ad2a-4822-a193-1b0be2ebf7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizar las preguntas usando TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(preguntas).toarray()\n",
    "\n",
    "# Crear el índice FAISS\n",
    "d = X.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b29ffb09-2d04-4bfc-9f88-38223e56ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_faq(query, k=5):\n",
    "    vec_query = vectorizer.transform([query]).toarray()\n",
    "    D, I = index.search(vec_query, k)\n",
    "    return D[0], [respuestas[i] for i in I[0]], [preguntas[i] for i in I[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "814677d7-cfbc-4370-b7f2-579142536bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_respuesta_cohere(pregunta, umbral=1):\n",
    "    # Buscar en el archivo JSON primero usando FAISS\n",
    "    distancias, respuestas_similares, preguntas_similares = buscar_faq(pregunta)\n",
    "    \n",
    "    # Usar la respuesta similar si la distancia es menor que el umbral\n",
    "    if distancias[0] < umbral:\n",
    "        return respuestas_similares[0]\n",
    "    \n",
    "    # Construir el contexto con las preguntas y respuestas similares\n",
    "    contexto = \"\\n\".join([f\"P: {preg}\\nR: {resp}\" for preg, resp in zip(preguntas_similares, respuestas_similares)])\n",
    "    \n",
    "    # Agregar la nueva pregunta al contexto\n",
    "    pregunta_contexto = f\"{contexto}\\nP: {pregunta}\\nR:\"\n",
    "    \n",
    "    # Usar Cohere para generar una respuesta\n",
    "    response = co.generate(\n",
    "        prompt=pregunta_contexto,\n",
    "        max_tokens=100,  # Permitir respuestas más largas\n",
    "        stop_sequences=[\"\\n\"],  # Parar la generación en una nueva línea\n",
    "        temperature=0.7,  # Aumentar la diversidad de la respuesta\n",
    "    )\n",
    "    return response.generations[0].text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1958ba6d-35ba-472d-8575-77a66af684fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debes tomar contacto con tu Director de Carrera para que canalice tu necesidad de cupos ante el Coordinador de Docencia o a su vez te informe cuales están disponible mismos que deben ser equivalentes.\n"
     ]
    }
   ],
   "source": [
    "query = \"¿historia?\"\n",
    "print(generar_respuesta_cohere(query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "598edaae-3018-48f1-b701-61e72db93cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('modelo_faiss.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'index': index,\n",
    "        'vectorizer': vectorizer,\n",
    "        'respuestas': respuestas\n",
    "    }, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb47624-f269-422d-8eb9-eeda86426537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado correctamente\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import cohere\n",
    "\n",
    "# Inicializar Cohere\n",
    "co = cohere.Client('OUxseEdjMfnqbmNkjQcNOcbLKkjFwHREtRJq72ZS')\n",
    "\n",
    "# Cargar los datos desde el archivo pickle\n",
    "with open('modelo_faiss.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    index = data['index']\n",
    "    vectorizer = data['vectorizer']\n",
    "    respuestas = data['respuestas']\n",
    "\n",
    "# Historial de conversación\n",
    "conversation_history = []\n",
    "print(\"Modelo cargado correctamente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43f353f3-2f7d-4643-a461-62b926a0edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_faq(query, k=1):\n",
    "    vec_query = vectorizer.transform([query]).toarray()\n",
    "    D, I = index.search(vec_query, k)\n",
    "    return D[0], [respuestas[i] for i in I[0]]\n",
    "\n",
    "def generar_respuesta_cohere(pregunta, umbral=0.7):\n",
    "    distancias, respuesta_similar = buscar_faq(pregunta)\n",
    "    \n",
    "    if distancias[0] < umbral:\n",
    "        return respuesta_similar[0]\n",
    "    \n",
    "    # Construir el contexto de la conversación\n",
    "    conversation = \"Universidad de las Fuerzas Armadas ESPE:\\n\"\n",
    "    for entry in conversation_history:\n",
    "        conversation += f\"{entry['role']}: {entry['message']}\\n\"\n",
    "    conversation += f\"Usuario: {pregunta}\\nRespuesta:\"\n",
    "    \n",
    "    response = co.generate(\n",
    "        prompt=conversation,\n",
    "        max_tokens=100,\n",
    "        stop_sequences=[\"\\n\"],\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    \n",
    "    return response.generations[0].text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "521e3e62-b0f9-40d1-8111-6cf0200e9354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'Usuario', 'message': '¿Cuál es la misión de la ESPE?'}, {'role': 'AI', 'message': 'Al 2025, ser reconocidos a nivel nacional e internacional como una institución de educación superior de calidad en docencia, investigación y vinculación bajo el paradigma de una universidad inteligente, articulando la transferencia de ciencia y tecnología, a través de procesos de I+D+i; y, convirtiéndonos en un referente de pensamiento en seguridad y defensa, al servicio del país y Fuerzas Armadas.'}, {'role': 'Usuario', 'message': '¿Quien es el directo de carrerta?'}, {'role': 'AI', 'message': 'El dirigir del cargo es colaborar con las dependencias correspondientes para lograr mejores recursos para el personal y el mantenimiento de los requerimentos generales de lasareas de mando de la UNIDAD especializada de la ESPE.'}, {'role': 'Usuario', 'message': '¿Quein es la directora de carrera?'}, {'role': 'AI', 'message': 'Dirigir la carrera es asesorar y mantener vigentes y de calidad todas las carreras oficiales de estudio ofrecidas por la UNIDAD especializada de la ESPE, con el fin de garantizar una educación que responda a las necesidades del personal de las Fuerzas Armadas y sus dependencias; así como la contrapuesta de los requisitos generales del'}]\n",
      "Dirigir la carrera es asesorar y mantener vigentes y de calidad todas las carreras oficiales de estudio ofrecidas por la UNIDAD especializada de la ESPE, con el fin de garantizar una educación que responda a las necesidades del personal de las Fuerzas Armadas y sus dependencias; así como la contrapuesta de los requisitos generales del\n"
     ]
    }
   ],
   "source": [
    "query = \"¿Quein es la directora de carrera?\"\n",
    "conversation_history.append({\"role\": \"Usuario\", \"message\": query})\n",
    "respuesta = generar_respuesta_cohere(query, umbral=0.7)\n",
    "conversation_history.append({\"role\": \"AI\", \"message\": respuesta})\n",
    "print(conversation_history)\n",
    "print(respuesta)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
